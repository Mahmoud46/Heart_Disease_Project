{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "097d91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from scipy.stats import loguniform\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30a76f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reduced dataset\n",
    "train_data = pd.read_csv('../data/reduced_dataset/reduced_train_data.csv')\n",
    "test_data = pd.read_csv('../data/reduced_dataset/reduced_test_data.csv')\n",
    "\n",
    "# Split to X_train, X_test, y_train, y_test\n",
    "X_train = train_data[train_data.columns[:-1]]\n",
    "X_test = test_data[test_data.columns[:-1]]\n",
    "\n",
    "y_train = train_data['goal']\n",
    "y_test = test_data['goal']\n",
    "\n",
    "# Prepare the train and test data\n",
    "X_train_scaled = X_train.to_numpy()\n",
    "X_test_scaled = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f1e8f8",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f802a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "344ce8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (GridSearchCV): {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Score: 0.8056737588652483\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "# Define a grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],      # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],          # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5]           # Minimum number of samples required to split a node\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_model,                # The model to optimize\n",
    "    param_grid=param_grid,       # The grid of parameters to try\n",
    "    cv=5,                        # Use 5-fold cross-validation\n",
    "    scoring='accuracy',          # Evaluate model performance using accuracy\n",
    "    n_jobs=-1                    # Use all available CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "# Run the grid search\n",
    "grid_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and best score found\n",
    "print(\"Best Parameters (GridSearchCV):\", grid_search_rf.best_params_)\n",
    "print(\"Best Score:\", grid_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73ddcaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (RandomizedSearchCV): {'max_depth': None, 'min_samples_split': 6, 'n_estimators': 202}\n",
      "Best Score: 0.8225177304964539\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV\n",
    "# Define distributions instead of fixed lists for random sampling\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),    # Randomly select from 100 to 499 trees\n",
    "    'max_depth': [None, 10, 20, 30],      # Choose from these fixed depth values\n",
    "    'min_samples_split': randint(2, 10)   # Randomly select split threshold between 2 and 9\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf_model,                    # The model to optimize\n",
    "    param_distributions=param_dist, # Parameter distributions to sample from\n",
    "    n_iter=20,                       # Try 20 random combinations\n",
    "    cv=5,                            # 5-fold cross-validation\n",
    "    scoring='accuracy',             # Use accuracy as the scoring metric\n",
    "    n_jobs=-1,                       # Use all CPU cores\n",
    "    random_state=42                 # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# Run the random search\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score found\n",
    "print(\"Best Parameters (RandomizedSearchCV):\", random_search_rf.best_params_)\n",
    "print(\"Best Score:\", random_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6082d",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6147580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca17ea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (GridSearchCV): {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score: 0.8398049645390072\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "# Define grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],                 # Inverse of regularization strength (smaller values = stronger regularization)\n",
    "    'penalty': ['l2'],                       # Type of regularization (L2 = Ridge)\n",
    "    'solver': ['lbfgs', 'liblinear']         # Optimization algorithm (lbfgs for multi-class, liblinear for binary/small data)\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=lr_model,          # The model to optimize\n",
    "    param_grid=param_grid,       # The grid of parameters to try\n",
    "    cv=5,                        # Use 5-fold cross-validation\n",
    "    scoring='accuracy',          # Evaluate model performance using accuracy\n",
    "    n_jobs=-1                    # Use all available CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "# Run the grid search\n",
    "grid_search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and best score found\n",
    "print(\"Best Parameters (GridSearchCV):\", grid_search_lr.best_params_)\n",
    "print(\"Best Score:\", grid_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de8a24f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (RandomizedSearchCV): {'C': 0.066904211664988, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score: 0.8398049645390072\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV\n",
    "# Define hyperparameter distributions\n",
    "param_dist = {\n",
    "    'C': loguniform(1e-3, 1e3),               # Sample C from a log-uniform distribution between 0.001 and 1000\n",
    "    'penalty': ['l2'],                        # Only L2 supported by lbfgs\n",
    "    'solver': ['lbfgs']                       # lbfgs supports multi-class problems and L2 penalty\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=lr_model,                     # Model to optimize\n",
    "    param_distributions=param_dist,  # Distributions for random sampling\n",
    "    n_iter=20,                        # Number of random combinations to try\n",
    "    cv=5,                             # 5-fold cross-validation\n",
    "    scoring='accuracy',              # Use accuracy for evaluation\n",
    "    n_jobs=-1,                        # Use all available cores\n",
    "    random_state=42                  # Set random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Run the random search\n",
    "random_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters (RandomizedSearchCV):\", random_search_lr.best_params_)\n",
    "print(\"Best Score:\", random_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad53d9",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d484329",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a661bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (GridSearchCV): {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Best Cross-Validated Accuracy: 0.7678191489361702\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "# Define the grid of hyperparameters\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 20],             # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],            # Minimum number of samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],              # Minimum number of samples required at a leaf node\n",
    "    'criterion': ['gini', 'entropy']            # Splitting strategy: 'gini' or 'entropy'\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search_dt = GridSearchCV(\n",
    "    estimator=dt_model,              # Model to optimize\n",
    "    param_grid=param_grid,     # Grid of hyperparameters to search\n",
    "    cv=5,                      # 5-fold cross-validation\n",
    "    scoring='accuracy',        # Use accuracy for scoring\n",
    "    n_jobs=-1                  # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Results\n",
    "print(\"Best Parameters (GridSearchCV):\", grid_search_dt.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", grid_search_dt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7814c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (RandomizedSearchCV): {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 6}\n",
      "Best Cross-Validated Accuracy: 0.7507978723404255\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV \n",
    "# Define hyperparameter distributions for random search\n",
    "param_dist = {\n",
    "    'max_depth': [None, 5, 10, 20, 30],               # Varying tree depth options\n",
    "    'min_samples_split': randint(2, 11),              # Random integers from 2 to 10\n",
    "    'min_samples_leaf': randint(1, 5),                # Random integers from 1 to 4\n",
    "    'criterion': ['gini', 'entropy']                  # Splitting criteria\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search_dt = RandomizedSearchCV(\n",
    "    estimator=dt_model,                     # Model to optimize\n",
    "    param_distributions=param_dist,  # Distributions to sample from\n",
    "    n_iter=20,                        # Number of random combinations to try\n",
    "    cv=5,                             # 5-fold cross-validation\n",
    "    scoring='accuracy',              # Accuracy scoring\n",
    "    n_jobs=-1,                        # Use all CPU cores\n",
    "    random_state=42                  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Results\n",
    "print(\"Best Parameters (RandomizedSearchCV):\", random_search_dt.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", random_search_dt.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6308fe4",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b55837c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54fa4388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (GridSearchCV): {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best Cross-Validated Accuracy: 0.8311170212765958\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV \n",
    "# Define the grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],                      # Regularization parameter (higher = less regularization)\n",
    "    'kernel': ['linear', 'rbf'],            # Type of kernel: linear or RBF (radial basis function)\n",
    "    'gamma': ['scale', 'auto']              # Kernel coefficient (only used with 'rbf')\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=svm_model,              # Model to optimize\n",
    "    param_grid=param_grid,      # Grid of hyperparameters\n",
    "    cv=5,                       # 5-fold cross-validation\n",
    "    scoring='accuracy',         # Accuracy as performance metric\n",
    "    n_jobs=-1                   # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Output best parameters and score\n",
    "print(\"Best Parameters (GridSearchCV):\", grid_search_svm.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", grid_search_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4f3bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (RandomizedSearchCV): {'C': 0.314891164795686, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Best Cross-Validated Accuracy: 0.8311170212765957\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV\n",
    "# Define distributions for random search\n",
    "param_dist = {\n",
    "    'C': loguniform(1e-2, 1e2),              # Log-uniform sampling for C between 0.01 and 100\n",
    "    'kernel': ['linear', 'rbf', 'poly'],     # Try multiple kernel types\n",
    "    'gamma': ['scale', 'auto']              # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search_svm = RandomizedSearchCV(\n",
    "    estimator=svm_model,                     # Model to optimize\n",
    "    param_distributions=param_dist,   # Parameter distributions\n",
    "    n_iter=20,                         # Number of random combinations to try\n",
    "    cv=5,                              # 5-fold cross-validation\n",
    "    scoring='accuracy',               # Accuracy metric\n",
    "    n_jobs=-1,                         # Use all CPU cores\n",
    "    random_state=42                   # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Output results\n",
    "print(\"Best Parameters (RandomizedSearchCV):\", random_search_svm.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", random_search_svm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa858cae",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8c3b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_metrics(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    confusion_matrix = np.array([[TN, FP],\n",
    "                   [FN, TP]])\n",
    "    \n",
    "    return [confusion_matrix, accuracy, precision, recall, f1_score]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ffff1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (GridSearchCV): 0.9\n",
      "Logistic Regression Accuracy (RandomizedSearchCV): 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Logistic Regression on test set\n",
    "# GridSearchCV\n",
    "gs_best_model_lr = grid_search_lr.best_estimator_\n",
    "y_pred = gs_best_model_lr.predict(X_test_scaled)\n",
    "_, accuracy, _, _, _ = binary_classification_metrics(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy (GridSearchCV):\", accuracy)\n",
    "\n",
    "# RandomizedSearchCV \n",
    "rs_best_model_lr = random_search_lr.best_estimator_\n",
    "y_pred = rs_best_model_lr.predict(X_test_scaled)\n",
    "_, accuracy, _, _, _ = binary_classification_metrics(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy (RandomizedSearchCV):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45bd1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy (GridSearchCV): 0.85\n",
      "Decision Tree Accuracy (RandomizedSearchCV): 0.7833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Decision Tree on test set\n",
    "# GridSearchCV\n",
    "gs_best_model_dt = grid_search_dt.best_estimator_\n",
    "y_pred = gs_best_model_dt.predict(X_test_scaled)\n",
    "_, accuracy, _, _, _ = binary_classification_metrics(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy (GridSearchCV):\", accuracy)\n",
    "\n",
    "# RandomizedSearchCV \n",
    "rs_best_model_dt = random_search_dt.best_estimator_\n",
    "y_pred = rs_best_model_dt.predict(X_test_scaled)\n",
    "_, accuracy, _, _, _ = binary_classification_metrics(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy (RandomizedSearchCV):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8fb47a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (GridSearchCV): 0.8666666666666667\n",
      "Random Forest Accuracy (RandomizedSearchCV): 0.8833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest on test set\n",
    "# GridSearchCV\n",
    "gs_best_model_rf = grid_search_rf.best_estimator_\n",
    "y_pred = gs_best_model_rf.predict(X_test_scaled)\n",
    "_, accuracy, _, _, _ = binary_classification_metrics(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy (GridSearchCV):\", accuracy)\n",
    "\n",
    "# RandomizedSearchCV \n",
    "rs_best_model_rf = random_search_rf.best_estimator_\n",
    "y_pred = rs_best_model_rf.predict(X_test_scaled)\n",
    "_, accuracy, _, _, _ = binary_classification_metrics(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy (RandomizedSearchCV):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e26ec725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy (GridSearchCV): 0.85\n",
      "SVM Accuracy (RandomizedSearchCV): 0.8833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SVM on test set\n",
    "# GridSearchCV\n",
    "gs_best_model_svm = grid_search_svm.best_estimator_\n",
    "y_pred = gs_best_model_svm.predict(X_test_scaled)\n",
    "_, accuracy, _, _, _ = binary_classification_metrics(y_test, y_pred)\n",
    "print(\"SVM Accuracy (GridSearchCV):\", accuracy)\n",
    "\n",
    "# RandomizedSearchCV \n",
    "rs_best_model_svm = random_search_svm.best_estimator_\n",
    "y_pred = rs_best_model_svm.predict(X_test_scaled)\n",
    "_, accuracy, _, _, _ = binary_classification_metrics(y_test, y_pred)\n",
    "print(\"SVM Accuracy (RandomizedSearchCV):\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23adaab1",
   "metadata": {},
   "source": [
    "### Table of comparison\n",
    "| Model       | Base model accuracy | Grid Search | RandomizedSearch |\n",
    "|-------------|---------------------|----------------------------|----------------------------------|\n",
    "| Logistic Regression    | 0.88                | 0.9                         | 0.9                             |\n",
    "| Random Forest     | 0.83                | 0.87                       | 0.88                             |\n",
    "| SVM     | 0.9                | 0.85                       | 0.88                             |\n",
    "| Decision Tree     | 0.85                | 0.85                       | 0.78                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad69c14",
   "metadata": {},
   "source": [
    "### Save best models with the heighest accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "763b160c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_models/best_logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rs_best_model_rf, '../models/best_models/best_random_forest_model.pkl')\n",
    "joblib.dump(gs_best_model_lr, '../models/best_models/best_logistic_regression_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
